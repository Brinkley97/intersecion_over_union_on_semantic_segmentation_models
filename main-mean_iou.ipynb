{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd9c8ac-92a0-4d65-88f5-8b9423c5a053",
   "metadata": {},
   "source": [
    "# Mean IOU for Semantic Segmetation Model\n",
    "- [Brinkley97/PixelLib model GitHub Repo](https://github.com/Brinkley97/sem_seg_pxLib_ade20k/blob/main/ssForImg.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3cbb70-8096-4578-8227-b170d62e72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b34605-6372-4e93-b835-d76f833db63e",
   "metadata": {},
   "source": [
    "## Load Semantic Segmetation Images\n",
    "- Update method to load multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78803d8-3e08-4b1c-8ddb-8ba638eebc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"trail-6_00001.png\"\n",
    "ground_truth_image = \"ground_truth_rural_input_images/\" + image\n",
    "prediction_model_image = \"m_seg_rural_input_images/\" + image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268d4a6-9402-472e-bf0d-e2bd98bed348",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- It's normal to resize the input images to fit models\n",
    "- Write code to resize, convert colors, etc... whatever is needed because we have a large input size and we can't pass all to an online converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9a413e-a30d-4df0-8e63-7fb1a12f08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objs_inside_img(ground_truth_image, prediction_model_image):\n",
    "    '''Determine the intersection over union when given a ground truth image and prediction model image\n",
    "    \n",
    "    Arguments:\n",
    "    ground_truth_image -- string\n",
    "    model_image -- string\n",
    "    \n",
    "    Return:\n",
    "    iou\n",
    "    \n",
    "    '''\n",
    "    \n",
    "#    print(type(ground_truth_image))\n",
    "#    print(type(prediction_model_image))\n",
    "    \n",
    "    '''\n",
    "    Pre process ground_truth image for MeanIOU\n",
    "    Get RGB to pass into TF MeanIOU function\n",
    "    '''\n",
    "    open_ground_truth_image = Image.open(ground_truth_image)\n",
    "    ground_truth_rgb = np.asarray(open_ground_truth_image)\n",
    "    print(\"ground_truth_rgb size:\", np.shape(ground_truth_rgb))\n",
    "#    print(\"ground_truth_rgb image:\", ground_truth_rgb)\n",
    "    \n",
    "    '''\n",
    "    Pre process prediction_model image for MeanIOU\n",
    "    Get RGB to pass into TF MeanIOU function\n",
    "    '''\n",
    "    open_prediction_model_image = Image.open(prediction_model_image)\n",
    "    prediction_model_rgb = np.asarray(open_prediction_model_image)\n",
    "    print(\"prediction_model_rgb size:\", np.shape(prediction_model_rgb))\n",
    "#    print(\"prediction_model_rgb image:\", prediction_model_rgb)\n",
    "    \n",
    "    '''\n",
    "    Compute the mean intersection over union with TF\n",
    "    https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU\n",
    "    update_state method: https://github.com/keras-team/keras/blob/v2.10.0/keras/metrics/metrics.py#L2686-L2736\n",
    "    '''\n",
    "      \n",
    "    mean_iou = tf.keras.metrics.MeanIoU(num_classes=25)\n",
    "    print(mean_iou)\n",
    "    mean_iou.update_state(ground_truth_rgb, prediction_model_rgb)\n",
    "    \n",
    "    return mean_iou.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ca1efa-7875-4fdc-b4b2-ae58a88684fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truth_rgb size: (550, 688, 3)\n",
      "prediction_model_rgb size: (449, 558, 4)\n",
      "MeanIoU(num_classes=25,name=mean_io_u,dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 07:46:43.034738: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "`labels` out of bound\nCondition x < y did not hold.\nFirst 3 elements of x:\n[  0 255   0]\nFirst 1 elements of y:\n[25]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mobjs_inside_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_model_image\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mobjs_inside_img\u001b[0;34m(ground_truth_image, prediction_model_image)\u001b[0m\n\u001b[1;32m     40\u001b[0m mean_iou \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMeanIoU(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_iou)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mmean_iou\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_model_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_iou\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/keras/utils/metrics_utils.py:70\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrying to run metric.update_state in replica context when \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake sure the keras Metric is created in TPUstrategy scope. \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 70\u001b[0m   update_op \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_state_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# update_op will be None in eager execution.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m   metric_obj\u001b[38;5;241m.\u001b[39madd_update(update_op)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/keras/metrics/base_metric.py:140\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m control_status \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    138\u001b[0m ag_update_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m    139\u001b[0m     obj_update_state, control_status)\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mag_update_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/keras/metrics/metrics.py:2494\u001b[0m, in \u001b[0;36m_IoUBase.update_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m   2491\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(sample_weight, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;66;03m# Accumulate the prediction to current confusion matrix.\u001b[39;00m\n\u001b[0;32m-> 2494\u001b[0m current_cm \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2495\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2496\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_cm\u001b[38;5;241m.\u001b[39massign_add(current_cm)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/iou/lib/python3.10/site-packages/tensorflow/python/ops/check_ops.py:407\u001b[0m, in \u001b[0;36m_binary_assert\u001b[0;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[1;32m    404\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     data \u001b[38;5;241m=\u001b[39m [message] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[0;32m--> 407\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[1;32m    408\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    409\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    410\u001b[0m       message\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_pretty_print(d, summarize) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data)))\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# not context.executing_eagerly()\u001b[39;00m\n\u001b[1;32m    413\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: `labels` out of bound\nCondition x < y did not hold.\nFirst 3 elements of x:\n[  0 255   0]\nFirst 1 elements of y:\n[25]"
     ]
    }
   ],
   "source": [
    "objs_inside_img(ground_truth_image, prediction_model_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32138f01-ea1d-4fdf-be77-0cd04acfce77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb6f01-9362-4a74-b8cb-bc62ef9530d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06540b5-8864-41b6-8791-138bc685985c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
